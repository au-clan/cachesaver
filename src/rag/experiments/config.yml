experiment_name: TEMP

data: test2_hotpotQA

cachesaver_config:
  batch_size: 20
  timeout: 2
  allow_batch_overflow: 1
  correctness: 0
  model_name: 'gpt-5-nano'

client_kwargs:
  #model_name: 'gpt-5-nano'
  n: 1
  decoding_params:
    temperature: 1.0
    max_completion_tokens: 10_000
    top_p: 1.0

query_augmentation:
  # Options: pass, synonym_extension, rewriting, hyde, decompose 
  component: pass
  kwargs:
    nr_synonyms: 3

retriever:
  # Options: sparse, dot_product, cosine_similarity, l2
  type: [dot_product]
  kwargs:
    k: [3]
    # should this be taken from the 'data' folder?
    embedding_model: sentence-transformers/all-MiniLM-L6-v2

context_builder:
  # Options: concat, cross_encoder
  component: concat
  kwargs: 
    k_context_builder: 6
    cross_enc_model_name: cross-encoder/ms-marco-MiniLM-L-6-v2 

