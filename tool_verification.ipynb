{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import asyncio\n",
    "from diskcache import Cache\n",
    "from groq import AsyncGroq\n",
    "from omegaconf import OmegaConf\n",
    "from cachesaver.pipelines import OnlineAPI\n",
    "from cachesaver.typedefs import Response, Batch\n",
    "from typing import Any, List\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from src.utils import tokens2cost\n",
    "from src.algorithms import *\n",
    "from src.models import OnlineLLM, API\n",
    "from src.typedefs import DecodingParameters, Model\n",
    "from src.tasks.game24 import EnvironmentGame24, AgentBfsGame24, AgentAggregateGame24, AgentEvaluateGame24, StateGame24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import RateLimitError\n",
    "\n",
    "class MockLLM(Model):\n",
    "    def __init__(self, client: Any, model: str)-> None:\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "\n",
    "    async def request(self, prompt: str, n: int, request_id: int, namespace: str, params: DecodingParameters) -> Response:\n",
    "        sleep = 1\n",
    "        while True:\n",
    "            try:\n",
    "                completion = await self.client.chat.completions.create(\n",
    "                    messages = [\n",
    "                        {\n",
    "                            \"role\" : \"user\",\n",
    "                            \"content\" : prompt\n",
    "                        }\n",
    "                    ],\n",
    "                    model = self.model,\n",
    "                    n = n,\n",
    "                    max_tokens= params.max_completion_tokens or None, # or None not needed but just to be explicit\n",
    "                    temperature = params.temperature or 1,\n",
    "                    stop = params.stop or None,\n",
    "                    top_p = params.top_p or 1,\n",
    "                    seed = 1234,\n",
    "                    logprobs = params.logprobs or False,\n",
    "                    top_logprobs = None,\n",
    "                )\n",
    "                break\n",
    "            except RateLimitError as e:\n",
    "                await asyncio.sleep(max(sleep, 90))\n",
    "                sleep *= 2\n",
    "            except Exception as e:\n",
    "                print(f\"Error {e}\")\n",
    "                raise e\n",
    "        input_tokens = completion.usage.prompt_tokens\n",
    "        completion_tokens = completion.usage.completion_tokens\n",
    "        response = [choice.message.content for choice in completion.choices]\n",
    "        return response\n",
    "    \n",
    "    async def batch_request(self, batch: Batch) -> List[Response]:\n",
    "        requests = [self.request(request) for request in batch.requests]\n",
    "        completions = await asyncio.gather(*requests)\n",
    "        return completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secret\n",
    "\n",
    "llm = \"llama-3.3-70b-versatile\"\n",
    "game_simple = \"10 10 1 4\"\n",
    "\n",
    "cache = Cache(f\"caches/game24\")\n",
    "\n",
    "client = AsyncGroq(api_key=secret.GROQ_API_KEYS[0])\n",
    "model = MockLLM(client=client, model=llm)\n",
    "# pipeline = OnlineAPI(\n",
    "#     model=model,\n",
    "#     cache=cache,\n",
    "#     batch_size=2,\n",
    "#     timeout=0.1,\n",
    "# )\n",
    "# api = API(\n",
    "#     pipeline=pipeline,\n",
    "#     model=llm\n",
    "# )\n",
    "\n",
    "state = StateGame24(\n",
    "    puzzle=game_simple,\n",
    "    current_state=game_simple,\n",
    "    steps=[],\n",
    "    randomness=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = DecodingParameters(\n",
    "    temperature=0.7,\n",
    "    max_completion_tokens=100,\n",
    "    top_p=1.0,\n",
    "    stop=None,\n",
    "    logprobs=False,\n",
    ")\n",
    "\n",
    "config = OmegaConf.load(\"scripts/game24.yaml\")\n",
    "\n",
    "agents = AgentDictGOT(\n",
    "    step=AgentBfsGame24,\n",
    "    aggregate=AgentAggregateGame24,\n",
    "    evaluate=AgentEvaluateGame24,\n",
    "    step_params=params,\n",
    "    aggregate_params=params,\n",
    "    eval_params=params,\n",
    ")\n",
    "method = AlgorithmGOT(\n",
    "    model=model,\n",
    "    agents=agents,\n",
    "    env=EnvironmentGame24,\n",
    "    num_selections=config.got.num_selections,\n",
    "    num_steps=config.got.num_steps,\n",
    "    num_best=config.got.num_best,\n",
    "    num_evaluations=config.got.num_evaluations,\n",
    ")\n",
    "\n",
    "# results = await method.solve(idx=0, state=state, namespace=\"small\", value_cache=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snippet of each method, to test them each and individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = AgentBfsGame24()\n",
    "aggregate = AgentAggregateGame24()\n",
    "evaluate = AgentEvaluateGame24()\n",
    "env = EnvironmentGame24()\n",
    "\n",
    "generate_results = await generate.act(model=model, state=state, namespace=\"small\", request_id=0, params=params)\n",
    "print(generate_results)\n",
    "\n",
    "proposals = []\n",
    "for action in generate_results:\n",
    "    proposals.append(env.step(state, action))\n",
    "\n",
    "aggregate_results = await aggregate.act(model=model, states=proposals, k=3, n=1, namespace=\"small\", request_id=0, params=params)\n",
    "print(aggregate_results)\n",
    "\n",
    "proposals = []\n",
    "for action in aggregate_results:\n",
    "    proposals.append(env.step(state, action))\n",
    "\n",
    "print(proposals)\n",
    "\n",
    "evaluate_coroutines = [evaluate.act(model=model, state=state, n=1, namespace=\"small\", request_id=0, params=params, cache=None) for state in proposals]\n",
    "evaluate_results = await asyncio.gather(*evaluate_coroutines)\n",
    "print(evaluate_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m env \u001b[38;5;241m=\u001b[39m EnvironmentGame24()\n\u001b[1;32m      6\u001b[0m state \u001b[38;5;241m=\u001b[39m StateGame24(\n\u001b[1;32m      7\u001b[0m     puzzle\u001b[38;5;241m=\u001b[39mgame_simple,\n\u001b[1;32m      8\u001b[0m     current_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10 14\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     steps\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     10\u001b[0m     randomness\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m generate_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m generate\u001b[38;5;241m.\u001b[39mact(model\u001b[38;5;241m=\u001b[39mmodel, state\u001b[38;5;241m=\u001b[39mstate, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m, request_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(generate_results)\n\u001b[1;32m     16\u001b[0m proposals \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "generate = AgentBfsGame24()\n",
    "aggregate = AgentAggregateGame24()\n",
    "evaluate = AgentEvaluateGame24()\n",
    "env = EnvironmentGame24()\n",
    "\n",
    "state = StateGame24(\n",
    "    puzzle=game_simple,\n",
    "    current_state=\"10 14\",\n",
    "    steps=[],\n",
    "    randomness=None,\n",
    ")\n",
    "\n",
    "generate_results = await generate.act(model=model, state=state, namespace=\"small\", request_id=0, params=params)\n",
    "print(generate_results)\n",
    "\n",
    "proposals = []\n",
    "for action in generate_results:\n",
    "    proposals.append(env.step(state, action))\n",
    "print(proposals)\n",
    "\n",
    "aggregate_results = await aggregate.act(model=model, states=proposals, k=3, n=1, namespace=\"small\", request_id=0, params=params)\n",
    "print(aggregate_results)\n",
    "\n",
    "proposals = []\n",
    "for action in aggregate_results:\n",
    "    proposals.append(env.step(state, action))\n",
    "\n",
    "print(proposals)\n",
    "\n",
    "evaluate_coroutines = [evaluate.act(model=model, state=state, n=1, namespace=\"small\", request_id=0, params=params, cache=None) for state in proposals]\n",
    "evaluate_results = await asyncio.gather(*evaluate_coroutines)\n",
    "print(evaluate_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
