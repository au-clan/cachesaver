api:
  model:
    model_name: llama-3.3-70b-versatile
    provider: Groq
  parameters:
    max_tokens: 50
    temperature: 0.7
    top_p: 1.0
    top_k: 50
    request_timeout: 120
    stop: Null

logs:
  log_name: developping
  log_dir: logs/game24/tot

framework: 
  name: Tree of Thoughts (ToT)
  evaluations: 3
  n_select_sample: 3

task:
  name: GameOf24
  min_steps: 4

run:
  set: mini
  repeats: 1
  debugging: null