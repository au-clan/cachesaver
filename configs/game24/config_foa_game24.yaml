api:
  model:
    model_name: llama-3.3-70b-versatile
    provider: Groq
  parameters:
    max_completion_tokens: 150
    temperature: 0.7
    top_p: 1.0
    stop: Null
    top_k: 50
    request_timeout: 120

logs:
  log_name: developping
  log_dir: logs/game24/foa

framework: 
  name: Fleet of Agents (FoA)
  num_agents: 3
  num_steps: 6
  k: 1
  backtrack: 0.5
  evaluations: 3
  resampling: linear_filtered
  origin: 120
  caching: True
  batching: True
  pruning: True

task:
  name: GameOf24
  min_steps: 4

run:
  set: mini
  repeats: 1
  debugging: Null